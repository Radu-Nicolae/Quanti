\documentclass[sigconf,review]{acmart}

\usepackage{amsmath,amssymb,amsfonts,latexsym}
\usepackage{enumerate}
\usepackage{xspace}
\usepackage{epsf,picinpar}
\usepackage{varioref}
\usepackage{colortbl,multirow,hhline}
\usepackage{listings}
\usepackage{amssymb}
\usepackage{colortbl,multirow,hhline}
\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage{caption}
\usepackage[normalem]{ulem}
\usepackage{xcolor}
\usepackage{pifont}
\usepackage{xcolor,colortbl}
\usepackage{url}
\usepackage{balance}
\usepackage{graphicx, subfigure}
\usepackage{longtable}
\usepackage{lscape}
\usepackage{multirow}
\usepackage{listings}
\usepackage{framed}
\usepackage{morefloats}
\usepackage[T1]{fontenc}
\usepackage{array}
\usepackage{pdfpages}
\usepackage{fancybox}
\usepackage{amsmath}
\usepackage{flushend}
\usepackage{booktabs}
\usepackage{enumitem}

\renewcommand{\ttdefault}{cmr}

%\newcommand{\limit}[1]{\textcolor{red}{\noindent \ding{46}~Page limit:~#1}\\}
\newcommand{\todo}[1]{\textcolor{blue}{\ding{46}~#1}} 
\newcommand{\ie}{\emph{i.e.,}\xspace}
\newcommand{\eg}{\emph{e.g.,}\xspace}
\newcommand{\etc}{etc.\xspace}
\newcommand{\etal}{\emph{et~al.}\xspace} 

\copyrightyear{2020}
\acmYear{2020}
\setcopyright{acmcopyright}
\acmConference[Green Lab 2020/2021]{Green Lab 2020/2021 - Vrije Universiteit Amsterdam}{September--October, 2025}{Amsterdam, The Netherlands}
\acmBooktitle{Green Lab 2020/2021 - Vrije Universiteit Amsterdam, September--October, 2025, Amsterdam (The Netherlands)}
    
\begin{document}

\begin{figure*}
    \centering
    \includegraphics[width=0.95\linewidth]{reportTemplate/figures/paper-page-budgeting-green-lab.pdf}
    \caption{Paper Page Budgeting following the template suggested in the work in progress paper by Iosup et al. in \cite{iosup-epema-systems-writing-wip}. Edit link: \url{https://drive.google.com/file/d/1-9jcqbOQJRCJZpWZldTrm27HNUFuAtWR/view?usp=drive_link}.}
    \label{fig:placeholder}
\end{figure*}

\newpage

\title{
Exploring the impact of LLM compression by quantization on energy consumption, resource utilisation, and accuracy
}

\author{Radu Nicolae}
\affiliation{%
 \institution{2760443 \\ VU Amsterdam, \\ Universiteit van Amsterdam}
} \email{r.nicolae@vu.nl}

\author{Muhammad Shayan}
\affiliation{%
 \institution{2891482 \\ VU Amsterdam}
} \email{m.shayan@student.vu.nl}

\author{Name Surname}
\affiliation{%
 \institution{Student Number \\ VU Amsterdam}
} \email{xyz@student.vu.nl}

\author{Name Surname}
\affiliation{%
 \institution{Student Number \\ VU Amsterdam}
} \email{xyz@student.vu.nl}

\author{Name Surname}
\affiliation{%
 \institution{Student Number \\ VU Amsterdam}
} \email{xyz@student.vu.nl}

\begin{abstract}
% \noindent \textit{Context}. 
% \todo{at the end}
Large Language Models (LLMs) are being increasingly adopted by our digital society, but raise sustainability concerns when operated at a massive societal scale, further exacerbating the exploitation of our already over-exploited resources. % societal context
To improve the performance, efficiency, and, thus, sustainability of LLMs, compression techniques have been widely adopted to minimise resource utilisation, especially when LLM workloads are not critical and extreme accuracy is not needed (e.g., users using LLMs for online searches). % LLM context
Quantisation is a widely used LLM compression technique adopted by industry-leading providers to reduce model size and, hence, reduce computation requirements, without requiring architectural LLM changes or LLM training, while still maintaining sufficient accuracy. % quantization context
However, albeit theoretically expected to exist, the tradeoffs between the energy efficiency, resource utilization (e.g., CPU, memory, inference time), and accuracy degradation of LLM operation remain insufficiently understood and unquantified. % gap 1
The benchmarking challenge is further exacerbated by the absence of benchmarking systems for systematically quantifying LLMs; the lack of such systems can be costly and could misguide operators of LLM services. % gap 2
Addressing the open challenge, in this work, we propose Quanti, the first tool for quantifying the sustainability and performance of LLMs. % approach (following AtLarge, community-standard methodology on designing distributed (eco)systems)
We propose an architecture for deploying, measuring, and comparing LLM on the server side. % design
Through experiments with a prototype, % implement
we % evaluate & experiment
(i) explore the impact of quantization on operational-level metrics of LLMs,
(ii) evaluate the tradeoff between energy consumption-accuracy of LLMs underlying different architectures, both original and under compression by quantization, and
(iii) quantify the impact of carbon-aware workload scheduling of compressed and uncompressed models. 
We research Quanti, together with all the  



% \noindent \textit{Goal}. 
% \todo{at the end}

% \noindent \textit{Method}. 
% \todo{at the end}

% \noindent \textit{Results}. 
% \todo{at the end}

% \noindent \textit{Conclusions}. 
% \todo{at the end}
\end{abstract}

\maketitle

\input{reportTemplate/sections/intro}
\input{reportTemplate/sections/related}
\input{reportTemplate/sections/definition}
\input{reportTemplate/sections/planning}
\input{reportTemplate/sections/execution}
\input{reportTemplate/sections/results}
\input{reportTemplate/sections/discussion}
\input{reportTemplate/sections/threats}
\input{reportTemplate/sections/conclusion} 

\bibliographystyle{IEEEtran}
\bibliography{references}

\end{document}
