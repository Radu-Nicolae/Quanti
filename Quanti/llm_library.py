# dictionary of models and the command for model

    # "Llama-2-7B"    : 'meta-llama/Llama-2-7b-chat-hf',      # https://huggingface.co/meta-llama/Llama-2-7b-chat-hf
    # "Granite-7B"    : 'instructlab/granite-7b-lab',         # https://huggingface.co/instructlab/granite-7b-lab
    # "Mistral-7B"    : 'mistralai/Mistral-7B-Instruct-v0.2', # https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.2
    # "Llama-2-7B-AWQ": 'TheBloke/Llama-2-7B-AWQ',            # https://huggingface.co/TheBloke/Llama-2-7B-AWQ
    # "Mistral-7B-AWQ": 'TheBloke/Mistral-7B-v0.1-AWQ',       # https://huggingface.co/TheBloke/Mistral-7B-v0.1-AWQ

models = {
    "Llama-3-8B"    : 'meta-llama/Llama-3.1-8B-Instruct',                   # https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct
    "Granite-8B"    : 'ibm-granite/granite-3.3-8b-base',                    # https://huggingface.co/ibm-granite/granite-3.3-8b-base
    "Mistral-8B"    : 'solidrust/Mistral-NeMo-Minitron-8B-Base-AWQ',        # https://huggingface.co/solidrust/Mistral-NeMo-Minitron-8B-Base-AWQ
    "Llama-3-8B-AWQ": 'hugging-quants/Meta-Llama-3.1-8B-Instruct-AWQ-INT4', # https://huggingface.co/hugging-quants/Meta-Llama-3.1-8B-Instruct-AWQ-INT4
    "Granite-8B-AWQ": 'RedHatAI/granite-3.1-8b-instruct-quantized.w4a16',   # https://huggingface.co/RedHatAI/granite-3.1-8b-instruct-quantized.w4a16,
    "Mistral-8B-AWQ": 'solidrust/Mistral-NeMo-Minitron-8B-Base-AWQ'         # https://huggingface.co/solidrust/Mistral-NeMo-Minitron-8B-Base-AWQ
}

